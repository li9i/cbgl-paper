%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Motivation}
\label{subsec:motivation}

The proposed method's motivation lies in the simple but powerful facts that are
in general exhibited through fig. \ref{fig:motivation_caer}: Let a pose
estimate of a 2D LIDAR sensor be within the given map (Def.
\ref{def:definition_0}); then the value of the CAER metric (Def.
\ref{def:definition_3}) between the scan measured by the sensor (Def.
\ref{def:definition_1}) and the map-scan captured from the estimate (Def.
\ref{def:definition_2}) is (a) proportional to both the estimate's location
error and orientation error in a neighbourhood of the sensor's true pose, and
(b) not inversely proportional to them outside of it. In other words comparing
any two pose estimates of the sensor's pose in terms of the CAER metric is
enough to establish a pose error hierarchy between them: a ranking.  This is
significant because: while the error of a single pose estimate is unknowable,
the top of a hierarchy of dense-enough pose estimates (Def.
\ref{def:definition_6}), ordered by CAER values, may provide the neighbourhood
of the desired pose, and hence an admissible estimate of the pose itself (Def.
\ref{def:definition_7}).  Moreover, the CAER metric is directly calculable
from the assumptions of Problem \ref{prob:the_problem}, with low computational
complexity $\mathcal{O}(N_s)$.
The relationships of proportionality between the CAER
metric of a pose estimate and its location and orientation errors have been
discovered and successfully exploited in the context of non-global
localisation, and specifically in pose-tracking, for the production of lidar
odometry \cite{Filotheou2022f} and the reduction of localisation's pose
estimate error \cite{Filotheou2023a}. In this context, estimate errors are
close to the origin, i.e. in contrast to the distribution of hypotheses' errors
in Monte Carlo methods.

Fig. \ref{fig:h_and_h_not_fig} (top) shows the relations between the total
errors of hypotheses and their (a) CAER values (left) and (b) ranks when ordered
by CAER ascending (right), which resulted from an experimental procedure
similar to that which produced fig. \ref{fig:motivation_caer}. The above
motivate investigation on whether the CAER metric could prove equally
beneficial in settings more uncertain than pose-tracking, that is, where the
location and orientation of pose estimates extend farther away from the
sensor's true location and orientation.



\begin{figure}\vspace{-1.5cm}
  \subfloat{\hspace{0.5cm}\input{./figures/caer_all.tex}}\vspace{-1.5cm}\\
  \subfloat{\hspace{-0.3cm}\input{./figures/face_bottom.tex}}
  \caption{\small Top: without loss of generality, a typical plot of the
           Cumulative Absolute Error per Ray metric (Eq. (\ref{eq:caer})) of
           $10^6$ hypotheses disperesed in the map of environment WAREHOUSE
           (Fig. \ref{fig:face} and section \ref{subsec:exp_b}). Bottom:
           focused view on hypotheses with location error close to the origin}
  \vspace{-0.5cm}
  \label{fig:motivation_caer}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The CBGL System}

In order to test the efficacy of the CAER metric in aiding the solution of
Problem \ref{prob:the_problem}, we introduce the CAER-Based Global Localisation
system (CBGL).\footnote{For a rigorous mathematical formulation of the
hypothesis underpinning CBGL see \cite{cbglarxiv}.} Given map $\bm{M}$, CBGL
first generates a set of pose hypotheses $\mathcal{H}$ (Def.
\ref{def:definition_0}). Their positions are randomly generated
uniformly within the map's traversable space; their orientations within
$[-\pi,\pi)$ rad. Then from these poses CBGL computes map-scans (Def.
\ref{def:definition_2}). Given these map-scans and a LIDAR's 2D measurement
$\mathcal{S}_R$ (Def. \ref{def:definition_1}), CBGL subsequently computes the
CAER value (Def. \ref{def:definition_3}) associated with each pose hypothesis.
It then ranks them in ascending order and selects the $k$ estimates with the
least CAER values in an attempt to estimate the $k$ hypotheses with the least
pose error (Alg. \ref{alg:bottom_k}). Estimation in this sense rests on the
motivation of subsection \ref{subsec:motivation}. Fig. \ref{fig:face} (bottom)
indicatively depicts such a pose hierarchy.

One challenge is choosing such $k$, $d_{\bm{l}}$, and $d_\alpha$ (Def.
\ref{def:definition_6}) that, given pose estimate error requirements
$\delta_{\bm{l}}$, $\delta_{\theta}$, CBGL produces admissible pose estimates
(Def. \ref{def:definition_7}) while being executed in timely manner.  Given the
method's Monte Carlo nature, optimistically, the only option for increasing the
accuracy of the final pose estimate by a factor of two would be to double
locational density $d_{\bm{l}}$; instead of doing that---and thereby doubling
the method's execution time---subsequent to the estimation of the pose
estimates with the $k$ lowest CAER values, CBGL scan--to--map-scan matches
the map-scans captured from them against the range scan measured by the real
sensor (\texttt{sm2}) \cite{Vasiljevic2016c,Filotheou2023a}.

Matching allows for (a) the correction of the pose of true positive estimates,
(b) by the same token the potential divergence of spurious, false positive,
pose estimates, and hence their elimination as pose estimate candidates, (c)
the decoupling of the final pose estimate's error from the method's chosen
densities, and (d) the production of finer pose estimates without excessive
increase in execution time. The principle of \texttt{sm2} is depicted in fig.
\ref{fig:sm2_evolution}.

The last step is the estimation of the one pose estimate with the least CAER
value within the group of $k$ matched estimates: CBGL's output. CBGL is
described in block diagram form in fig.  \ref{fig:block_system} and in
pseudocode in Algorithm \ref{alg:cbgl}.

\begin{figure}[]\vspace{1.5cm}
  \input{./figures/characterisation/sm2_evolution.tex}
  \caption{\small Depiction of the process of scan--to--map-scan matching
           (\texttt{sm2}) in principle, which takes place for all
           $\hat{\bm{p}}_i = \mathcal{H}_1[i]$, $i=0,1,\dots,k$$-$$1$ (Alg.
           \ref{alg:cbgl}). The registration of map-scan
           $\mathcal{S}_V^{\bm{M}}(\hat{\bm{p}}[s])$ to $\mathcal{S}_R$ at step
           $s$ results in pose $\hat{\bm{p}}[s$$+$$1]$, where
           $\hat{\bm{p}}_i[0] = \mathcal{H}_1[i]$. The error of
           $\hat{\bm{p}}[s$$+$$1]$ is, in principle, reduced compared to
           $\hat{\bm{p}}[s]$, and the next map-scan is captured from it. The
           process is iterative and completes upon estimate convergence}
  \label{fig:sm2_evolution}
\end{figure}


%%% CBGL %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{algorithm}[]
  \caption{\texttt{CBGL}}
  \begin{spacing}{1.0}
  \begin{algorithmic}[1]
    \REQUIRE $\mathcal{S}_R$, $\lambda$, $\bm{M}$, $(d_{\bm{l}}, d_\alpha)$, $k$
    \ENSURE Pose estimate of sensor measuring range scan $\mathcal{S}_R$ %$\hat{\bm{p}}$
    \STATE $A \leftarrow \texttt{calculate\_area}(\texttt{free}(\bm{M}))$
    \STATE $\mathcal{H}, \mathcal{H}_1, \mathcal{H}_2 \leftarrow \{\varnothing\}$
    \FOR {$i \leftarrow 0,1,\dots,d_{\bm{l}} \cdot A-1$}
      \STATE \small $(\hat{x},\hat{y},\hat{\theta}) \leftarrow \texttt{rand()}$: $(x,y) \in \texttt{free}(\bm{M})$, $\hat{\theta} \in [-\pi,+\pi)$
      \FOR {$j \leftarrow 0,1,\dots, d_{\alpha}-1$}
        \STATE $\mathcal{H} \leftarrow \{\mathcal{H}, (\hat{x}, \hat{y}, \hat{\theta} + j \cdot 2\pi / d_{\alpha})\}$     \label{alg:cbgl:h}
      \ENDFOR
    \ENDFOR
    \STATE $\mathcal{H}_1 \leftarrow$ \texttt{bottom}$\_k\_\texttt{poses}(\mathcal{S}_R, \bm{M}, \mathcal{H}, k, \lambda)$ \hfill {\small (Alg. \ref{alg:bottom_k}}) \label{alg:cbgl:h1}
    \FOR {$k \leftarrow 0,1,\dots,|\mathcal{H}_1|-1$}
      %\STATE $\hat{\bm{h}}^\prime \leftarrow \texttt{sm2}(\mathcal{S}_R, \lambda, \bm{M}, \mathcal{H}_1[k])$ \hfill {\small (Alg. \ref{alg:sm2}---e.g. \texttt{x1} \cite{Filotheou2023a}})
      %\STATE $\mathcal{H}_2 \leftarrow \{\mathcal{H}_2, \hat{\bm{h}}^\prime\}$  \label{alg:cbgl:h2}
      \STATE \footnotesize $\mathcal{H}_2 \leftarrow \{\mathcal{H}_2, \texttt{sm2}(\mathcal{S}_R, \lambda, \bm{M}, \mathcal{H}_1[k])\}$ \hfill {(Alg. \ref{alg:sm2}---e.g. \texttt{x1} \cite{Filotheou2023a})}\label{alg:cbgl:h2}
    \ENDFOR
    \RETURN \texttt{bottom}$\_k\_\texttt{poses}(\mathcal{S}_R, \bm{M}, \mathcal{H}_2, 1, \lambda)$
  \end{algorithmic}
  \end{spacing}
  \label{alg:cbgl}
\end{algorithm}




\begin{figure}\vspace{-0.4cm}
  \subfloat{\label{fig:cbgl}     \input{./figures/cbgl_system_tiny.tikz}}
  \subfloat{\label{fig:bottom_k} \input{./figures/inner_ranking_system2_tiny.tikz}}
  \caption{\small CBGL in block diagram form. Left: Given map $\bm{M}$, CBGL
           first generates a set of pose hypotheses $\mathcal{H}$. Then it
           estimates the $k$ hypotheses with the least pose error (right; Alg.
           \ref{alg:bottom_k}).
           %II \cite{Filotheou2023c}
           As a final step, it scan--to--map-scan
           matches these to $\mathcal{S}_R$ for finer estimation
           (Alg. \ref{alg:sm2}).
           %III \cite{Filotheou2023c}
           CBGL's output pose estimate is that with
           the minimum CAER among the $k$ matched estimates. See Algs.
           \ref{alg:cbgl}, \ref{alg:bottom_k}, \ref{alg:sm2} for notation
           }
  \label{fig:block_system}
\end{figure}





%% Bottom-n %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{algorithm}[]
  \caption{\texttt{bottom}\_$k$\_\texttt{poses}}
  \begin{spacing}{1.0}
  \begin{algorithmic}[1]
    \REQUIRE $\mathcal{S}_R$, $\bm{M}$, $\mathcal{P}$, $k$, $\lambda$
    \ENSURE Set of $k$ poses of $\mathcal{P}$ with least CAER values, $\mathcal{P}_{\triangledown}$
    \STATE $\Psi \leftarrow \{\varnothing \}$
    \FOR {$q \leftarrow 0,1,\dots,|\mathcal{P}|-1$}
      \STATE $\mathcal{S}_V^{\hspace{1pt} q} \leftarrow \mathcal{S}_V^{\bm{M}}(\mathcal{P}[q]) = \texttt{scan\_map}(\bm{M}, \mathcal{P}[q], \lambda)$
      \STATE $\Psi \leftarrow \{\Psi, \texttt{CAER}(\mathcal{S}_R, \mathcal{S}_V^{\hspace{1pt} q}) \}$ \hfill {\small (Eq. (\ref{eq:caer})})
    \ENDFOR
    \STATE $[\Psi_{\uparrow}, \texttt{I}^{\ast}] \leftarrow \texttt{sort}(\Psi, \texttt{asc})$, such that $\Psi[\texttt{I}^{\ast}] = \Psi_{\uparrow}$
    \RETURN $\mathcal{P}_{\triangledown} = \{\mathcal{P}[\texttt{I}^{\ast}[0]], \mathcal{P}[\texttt{I}^{\ast}[1]], \dots, \mathcal{P}[\texttt{I}^{\ast}[k-1]]\}$
    %\RETURN $\mathcal{P}_{\triangledown}$
  \end{algorithmic}
  \end{spacing}
  \label{alg:bottom_k}
\end{algorithm}

%% sm2 %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{algorithm}[]
  \caption{\texttt{sm2}}
  \begin{spacing}{1.0}
  \begin{algorithmic}[1]
    \REQUIRE $\mathcal{S}_R$, $\lambda$, $\bm{M}$, $\hat{\bm{p}}$
    %\ENSURE $\hat{\bm{p}}^\prime$
    \ENSURE $\hat{\bm{p}}$ $+$ correction that aligns $\mathcal{S}_V^{\bm{M}}(\hat{\bm{p}})$ to $\mathcal{S}_R$
    \STATE $\mathcal{S}_V \leftarrow \texttt{scan\_map}(\bm{M}, \hat{\bm{p}}, \lambda)$
    \STATE $\bm{\Delta p} \leftarrow \texttt{scan-match}(\mathcal{S}_R,\mathcal{S}_V)$ \hfill {\footnotesize (e.g. \texttt{ICP}\cite{Vizzo2023}, \texttt{FSM}\cite{Filotheou2022f}})
    %\STATE $\hat{\bm{p}}^\prime \leftarrow \hat{\bm{p}} + \bm{\Delta p}$
    %\RETURN $\hat{\bm{p}}^\prime$
    \RETURN $\hat{\bm{p}} + \bm{\Delta p}$
  \end{algorithmic}
  \end{spacing}
  \label{alg:sm2}
\end{algorithm}
